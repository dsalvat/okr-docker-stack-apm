import uuid
import json
from app.services.scoring import score_objective, score_kr
from app.services.ai_service import llm_feedback
from app.db.session import SessionLocal
from app.db.models import OkrSubmission, KeyResult

async def evaluate_objective(objective: str):
    # 游댠 PROMPT MEJORADO - M츼S DETALLADO Y VALIOSO
    json_prompt = f"""
Eres un consultor experto en OKRs con 15 a침os de experiencia. Eval칰a este objetivo empresarial: "{objective}"

Analiza el objetivo usando el framework SMART y proporciona una evaluaci칩n detallada y accionable.

Responde 칔NICAMENTE en formato JSON v치lido con esta estructura EXACTA:
{{
    "score": [n칰mero del 1-10 basado en promedio de criterios],
    "feedback": "Evaluaci칩n general detallada en 4-6 l칤neas que explique las fortalezas principales, las debilidades cr칤ticas y el potencial impacto del objetivo",
    "criteria": {{
        "specific": {{
            "score": [1-10],
            "comment": "An치lisis detallado de 30-40 palabras sobre claridad, concreci칩n y especificidad del objetivo"
        }},
        "measurable": {{
            "score": [1-10], 
            "comment": "An치lisis detallado de 30-40 palabras sobre m칠tricas, cuantificaci칩n y capacidad de medici칩n"
        }},
        "achievable": {{
            "score": [1-10],
            "comment": "An치lisis detallado de 30-40 palabras sobre realismo, recursos necesarios y factibilidad"
        }},
        "relevant": {{
            "score": [1-10],
            "comment": "An치lisis detallado de 30-40 palabras sobre alineaci칩n estrat칠gica e impacto empresarial"
        }},
        "timebound": {{
            "score": [1-10],
            "comment": "An치lisis detallado de 30-40 palabras sobre marco temporal, urgencia y deadlines"
        }}
    }},
    "suggestions": [
        "Sugerencia espec칤fica y accionable 1 (15-25 palabras con pasos concretos)",
        "Sugerencia espec칤fica y accionable 2 (15-25 palabras con pasos concretos)",
        "Sugerencia espec칤fica y accionable 3 (15-25 palabras con pasos concretos)",
        "Sugerencia espec칤fica y accionable 4 (15-25 palabras con pasos concretos)"
    ]
}}

REQUISITOS CR칈TICOS:
- S칠 espec칤fico y detallado en cada an치lisis
- Proporciona insights accionables que ayuden a mejorar el objetivo
- Usa un tono profesional pero accesible
- Cada criterio debe tener comentarios de 30-40 palabras m칤nimo
- Las sugerencias deben ser implementables inmediatamente
- Responde SOLO el JSON, sin texto adicional antes o despu칠s
"""

    # Mantener scoring heur칤stico existente para base de datos
    heur = score_objective(objective)
    
    # 游댠 NUEVA EVALUACI칍N JSON ESTRUCTURADA
    try:
        # Obtener evaluaci칩n JSON estructurada de la IA
        json_response = await llm_feedback(json_prompt)
        
        # Intentar parsear como JSON
        try:
            ai_evaluation = json.loads(json_response)
        except json.JSONDecodeError:
            # Si no es JSON v치lido, crear estructura por defecto
            ai_evaluation = {
                "score": heur["total"],
                "feedback": f"Evaluaci칩n t칠cnica: Score {heur['total']}/10 basado en claridad, enfoque y redacci칩n.",
                "criteria": {
                    "specific": {"score": heur.get("clarity", 5), "comment": "An치lisis de especificidad basado en heur칤stica"},
                    "measurable": {"score": heur.get("focus", 5), "comment": "An치lisis de medibilidad basado en heur칤stica"},
                    "achievable": {"score": max(1, min(10, heur["total"] - 1)), "comment": "An치lisis de factibilidad estimado"},
                    "relevant": {"score": heur.get("focus", 5), "comment": "An치lisis de relevancia basado en enfoque"},
                    "timebound": {"score": heur.get("writing", 5), "comment": "An치lisis temporal basado en redacci칩n"}
                },
                "suggestions": [
                    "Mejorar la claridad del objetivo",
                    "A침adir m칠tricas espec칤ficas",
                    "Definir timeline m치s concreto"
                ]
            }
        
        # Tambi칠n obtener feedback tradicional para DB (mantener compatibilidad)
        fb = await llm_feedback(f"Avalua OBJECTIU d'OKR i proposa millores. Text: '{objective}'. Notes: {', '.join(heur['notes']) or 'Sense notes'}")
        
    except Exception as e:
        # En caso de error con IA, usar valores por defecto
        ai_evaluation = {
            "score": heur["total"],
            "feedback": f"Error en evaluaci칩n IA. Score heur칤stico: {heur['total']}/10",
            "criteria": {
                "specific": {"score": heur.get("clarity", 5), "comment": "Error en an치lisis espec칤fico"},
                "measurable": {"score": heur.get("focus", 5), "comment": "Error en an치lisis de medibilidad"},
                "achievable": {"score": 5, "comment": "Error en an치lisis de factibilidad"},
                "relevant": {"score": heur.get("focus", 5), "comment": "Error en an치lisis de relevancia"},
                "timebound": {"score": heur.get("writing", 5), "comment": "Error en an치lisis temporal"}
            },
            "suggestions": ["Error obteniendo sugerencias", "Intenta reformular el objetivo"]
        }
        fb = f"Error evaluando objetivo: {str(e)}"
    
    # Generar ID y guardar en DB (mantener funcionalidad existente)
    okr_id = str(uuid.uuid4())
    with SessionLocal() as db:
        db.add(OkrSubmission(
            id=okr_id, 
            objective=objective,
            clarity=heur['clarity'], 
            focus=heur['focus'], 
            writing=heur['writing'],
            score=heur['total'], 
            feedback=fb
        ))
        db.commit()
    
    # 游댠 DEVOLVER RESPUESTA PARA FRONTEND + DATOS LEGACY
    return {
        # Datos para el frontend React (nueva UI)
        "score": ai_evaluation["score"],
        "feedback": ai_evaluation["feedback"],
        "criteria": ai_evaluation["criteria"],
        "suggestions": ai_evaluation["suggestions"],
        
        # Datos legacy para compatibilidad (si otros servicios los usan)
        "okr_id": okr_id,
        "breakdown": {
            "clarity": heur["clarity"], 
            "focus": heur["focus"], 
            "writing": heur["writing"]
        },
        "can_add_krs": heur["total"] >= 7.5
    }

async def evaluate_kr(okr_id: str, kr_definition: str, target_value: str, target_date: str):
    # Mantener funcionalidad existente de KR sin cambios
    heur = score_kr(kr_definition, target_value, target_date)
    fb = await llm_feedback(f"Avalua RESULTAT CLAU d'OKR. KR: '{kr_definition}'; Valor: {target_value}; Data: {target_date}. Dona 3-6 millores concretes.")
    kr_id = str(uuid.uuid4())
    with SessionLocal() as db:
        db.add(KeyResult(
            id=kr_id, okr_id=okr_id, kr_definition=kr_definition,
            target_value=target_value, target_date=target_date,
            clarity=heur['clarity'], measurability=heur['measurability'], feasibility=heur['feasibility'],
            score=heur['total'], feedback=fb
        ))
        db.commit()
    return {
        "key_result_id": kr_id,
        "score": heur["total"],
        "breakdown": {"clarity": heur["clarity"], "measurability": heur["measurability"], "feasibility": heur["feasibility"]},
        "feedback": fb,
        "allow_next_kr": heur["total"] >= 7.5
    }