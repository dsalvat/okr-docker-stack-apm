import uuid
import json
from datetime import datetime
from app.services.scoring import score_objective, score_kr
from app.services.ai_service import llm_feedback
from app.db.session import SessionLocal
from app.db.models import OkrSubmission, KeyResult
import logging

logger = logging.getLogger(__name__)

async def evaluate_objective(objective: str):
    """
    EvalÃºa un objetivo usando IA y devuelve estructura compatible con frontend.
    """
    
    # ðŸ”¥ PROMPT OPTIMIZADO PARA JSON CONSISTENTE
    json_prompt = f"""
Eres un consultor experto en OKRs con 15 aÃ±os de experiencia. EvalÃºa este objetivo empresarial: "{objective}"

Analiza el objetivo usando el framework SMART y proporciona una evaluaciÃ³n detallada y accionable.

Responde ÃšNICAMENTE en formato JSON vÃ¡lido con esta estructura EXACTA:
{{
    "overall_score": [nÃºmero del 1-10 con 1 decimal],
    "feedback": "EvaluaciÃ³n general detallada en 4-6 lÃ­neas que explique las fortalezas principales, las debilidades crÃ­ticas y el potencial impacto del objetivo",
    "criteria": {{
        "specific": {{
            "score": [1-10],
            "comment": "AnÃ¡lisis detallado de 30-40 palabras sobre claridad, concreciÃ³n y especificidad del objetivo"
        }},
        "measurable": {{
            "score": [1-10], 
            "comment": "AnÃ¡lisis detallado de 30-40 palabras sobre mÃ©tricas, cuantificaciÃ³n y capacidad de mediciÃ³n"
        }},
        "achievable": {{
            "score": [1-10],
            "comment": "AnÃ¡lisis detallado de 30-40 palabras sobre realismo, recursos necesarios y factibilidad"
        }},
        "relevant": {{
            "score": [1-10],
            "comment": "AnÃ¡lisis detallado de 30-40 palabras sobre alineaciÃ³n estratÃ©gica e impacto empresarial"
        }},
        "timebound": {{
            "score": [1-10],
            "comment": "AnÃ¡lisis detallado de 30-40 palabras sobre marco temporal, urgencia y deadlines"
        }}
    }},
    "suggestions": [
        "Sugerencia especÃ­fica y accionable 1 (15-25 palabras con pasos concretos)",
        "Sugerencia especÃ­fica y accionable 2 (15-25 palabras con pasos concretos)",
        "Sugerencia especÃ­fica y accionable 3 (15-25 palabras con pasos concretos)",
        "Sugerencia especÃ­fica y accionable 4 (15-25 palabras con pasos concretos)"
    ]
}}

REQUISITOS CRÃTICOS:
- SÃ© especÃ­fico y detallado en cada anÃ¡lisis
- Proporciona insights accionables que ayuden a mejorar el objetivo
- Usa un tono profesional pero accesible
- Cada criterio debe tener comentarios de 30-40 palabras mÃ­nimo
- Las sugerencias deben ser implementables inmediatamente
- Responde SOLO el JSON, sin texto adicional antes o despuÃ©s
"""

    # Scoring heurÃ­stico para base de datos
    heur = score_objective(objective)
    okr_id = str(uuid.uuid4())
    
    # ðŸ”¥ LLAMADA A IA CON MANEJO DE ERRORES ROBUSTO
    try:
        ai_response = await llm_feedback(json_prompt)
        logger.info(f"ðŸ” Respuesta IA recibida para OKR {okr_id}")
        
        # ðŸ”¥ PARSEAR JSON CON VALIDACIÃ“N
        try:
            ai_data = json.loads(ai_response)
            
            # Validar que tenemos los campos esenciales
            required_fields = ['overall_score', 'feedback', 'criteria', 'suggestions']
            missing_fields = [field for field in required_fields if field not in ai_data]
            
            if missing_fields:
                raise ValueError(f"Faltan campos requeridos: {missing_fields}")
            
            # Validar estructura de criteria
            required_criteria = ['specific', 'measurable', 'achievable', 'relevant', 'timebound']
            criteria = ai_data.get('criteria', {})
            for criterion in required_criteria:
                if criterion not in criteria:
                    criteria[criterion] = {"score": 5, "comment": f"Error: criterio {criterion} no evaluado"}
                elif not isinstance(criteria[criterion], dict):
                    criteria[criterion] = {"score": 5, "comment": f"Error: formato incorrecto para {criterion}"}
                elif 'score' not in criteria[criterion] or 'comment' not in criteria[criterion]:
                    criteria[criterion] = {
                        "score": criteria[criterion].get('score', 5),
                        "comment": criteria[criterion].get('comment', f"Comentario no disponible para {criterion}")
                    }
            
            logger.info(f"âœ… JSON parseado exitosamente. Score: {ai_data['overall_score']}")
            logger.info(f"âœ… Feedback length: {len(ai_data.get('feedback', ''))}")
            logger.info(f"âœ… Criteria keys: {list(ai_data.get('criteria', {}).keys())}")
            logger.info(f"âœ… Suggestions count: {len(ai_data.get('suggestions', []))}")
            
        except (json.JSONDecodeError, ValueError, KeyError) as e:
            logger.error(f"âŒ Error parsing JSON: {e}")
            logger.error(f"âŒ Respuesta que fallÃ³: {ai_response[:500]}...")
            
            # Fallback con datos heurÃ­sticos estructurados
            ai_data = {
                "overall_score": float(heur["total"]),
                "feedback": f"Error en anÃ¡lisis de IA. EvaluaciÃ³n heurÃ­stica: {heur['total']}/10 puntos. El objetivo requiere revisiÃ³n manual para anÃ¡lisis completo.",
                "criteria": {
                    "specific": {
                        "score": float(heur.get("clarity", 5)), 
                        "comment": "AnÃ¡lisis automÃ¡tico basado en claridad del texto. Se recomienda revisiÃ³n manual."
                    },
                    "measurable": {
                        "score": float(heur.get("focus", 5)), 
                        "comment": "AnÃ¡lisis automÃ¡tico basado en enfoque detectado. Verificar mÃ©tricas especÃ­ficas."
                    },
                    "achievable": {
                        "score": 5.0, 
                        "comment": "AnÃ¡lisis automÃ¡tico - requiere evaluaciÃ³n manual del contexto empresarial."
                    },
                    "relevant": {
                        "score": float(heur.get("focus", 5)), 
                        "comment": "AnÃ¡lisis automÃ¡tico basado en relevancia percibida. Validar alineaciÃ³n estratÃ©gica."
                    },
                    "timebound": {
                        "score": float(heur.get("writing", 5)), 
                        "comment": "AnÃ¡lisis automÃ¡tico basado en redacciÃ³n. Verificar timeline especÃ­fico."
                    }
                },
                "suggestions": [
                    "Revisar la especificidad del objetivo con mÃ©tricas concretas",
                    "AÃ±adir indicadores cuantificables y fechas lÃ­mite claras",
                    "Evaluar la factibilidad con recursos y capacidades disponibles",
                    "Establecer hitos intermedios y timeline detallado de implementaciÃ³n"
                ]
            }
            
    except Exception as e:
        logger.error(f"âŒ Error en llamada IA: {e}")
        
        # Fallback de emergencia con estructura completa
        ai_data = {
            "overall_score": float(heur["total"]),
            "feedback": f"Error en servicio de IA. PuntuaciÃ³n heurÃ­stica: {heur['total']}/10. Contactar soporte tÃ©cnico para anÃ¡lisis completo.",
            "criteria": {
                "specific": {
                    "score": float(heur.get("clarity", 5)), 
                    "comment": "Error en anÃ¡lisis especÃ­fico - revisar conectividad con servicio de IA"
                },
                "measurable": {
                    "score": float(heur.get("focus", 5)), 
                    "comment": "Error en anÃ¡lisis de mediciÃ³n - validar configuraciÃ³n del sistema"
                },
                "achievable": {
                    "score": 5.0, 
                    "comment": "Error en anÃ¡lisis de factibilidad - requiere evaluaciÃ³n manual"
                },
                "relevant": {
                    "score": float(heur.get("focus", 5)), 
                    "comment": "Error en anÃ¡lisis de relevancia - verificar configuraciÃ³n de servicio"
                },
                "timebound": {
                    "score": float(heur.get("writing", 5)), 
                    "comment": "Error en anÃ¡lisis temporal - contactar administrador del sistema"
                }
            },
            "suggestions": [
                "Error obteniendo sugerencias - revisar configuraciÃ³n del servicio de IA",
                "Contactar soporte tÃ©cnico para anÃ¡lisis detallado del objetivo",
                "Verificar conectividad y configuraciÃ³n del sistema",
                "Intentar evaluaciÃ³n manual mientras se resuelve el problema tÃ©cnico"
            ]
        }
        ai_response = f"Error: {str(e)}"

    # Guardar en base de datos
    try:
        with SessionLocal() as db:
            db.add(OkrSubmission(
                id=okr_id,
                objective=objective,
                clarity=heur['clarity'],
                focus=heur['focus'],
                writing=heur['writing'],
                score=heur['total'],
                feedback=ai_data.get("feedback", "Error guardando feedback")
            ))
            db.commit()
            logger.info(f"ðŸ’¾ OKR guardado en BD con ID: {okr_id}")
    except Exception as e:
        logger.error(f"âŒ Error guardando en BD: {e}")

    # ðŸ”¥ ESTRUCTURA FINAL COMPATIBLE CON FRONTEND
    result = {
        # Datos principales (estructura que espera el frontend)
        "score": ai_data["overall_score"],
        "feedback": ai_data["feedback"],
        "criteria": ai_data["criteria"],
        "suggestions": ai_data["suggestions"],
        
        # Debug info (para desarrollo)
        "debug_ai_response": ai_response,
        "debug_parsed": ai_data,
        
        # Metadata adicional
        "okr_id": okr_id,
        "model_used": "gpt-4o-mini",
        "timestamp": datetime.utcnow().isoformat(),
        "status": "success",
        
        # Legacy compatibility (para funcionalidades existentes)
        "breakdown": {
            "clarity": heur["clarity"],
            "focus": heur["focus"],
            "writing": heur["writing"]
        },
        "can_add_krs": ai_data["overall_score"] >= 7.5
    }
    
    logger.info(f"ðŸŽ¯ RESULTADO FINAL - ID: {okr_id}, Score: {result['score']}")
    return result


async def evaluate_kr(okr_id: str, kr_definition: str, target_value: str, target_date: str):
    """EvalÃºa un Key Result - mantener funcionalidad existente"""
    try:
        heur = score_kr(kr_definition, target_value, target_date)
        fb = await llm_feedback(f"Avalua RESULTAT CLAU d'OKR. KR: '{kr_definition}'; Valor: {target_value}; Data: {target_date}. Dona 3-6 millores concretes.")
        kr_id = str(uuid.uuid4())
        
        with SessionLocal() as db:
            db.add(KeyResult(
                id=kr_id, okr_id=okr_id, kr_definition=kr_definition,
                target_value=target_value, target_date=target_date,
                clarity=heur['clarity'], measurability=heur['measurability'], 
                feasibility=heur['feasibility'], score=heur['total'], feedback=fb
            ))
            db.commit()
            
        return {
            "key_result_id": kr_id,
            "score": heur["total"],
            "breakdown": {
                "clarity": heur["clarity"], 
                "measurability": heur["measurability"], 
                "feasibility": heur["feasibility"]
            },
            "feedback": fb,
            "allow_next_kr": heur["total"] >= 7.5
        }
    except Exception as e:
        logger.error(f"Error evaluating KR: {e}")
        raise